{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXNWSwZz3/L7Oy0DB8u/Tp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeaneigsi/cookbook/blob/main/RunOnnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PbeK23G2rVEY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVEzlcVzfSYA",
        "outputId": "91a80106-5ef2-410a-cdda-19425c56d297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '-'...\n",
            "fatal: repository 'https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/tree/main/cuda/' not found\n"
          ]
        }
      ],
      "source": [
        "!git clone https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/tree/main/cuda -"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install --pre onnxruntime-genai"
      ],
      "metadata": {
        "id": "OS7trs4Qfg50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install --pre onnxruntime-genai-directml"
      ],
      "metadata": {
        "id": "36NHGllbl1hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://github.com/microsoft/onnxruntime-genai/blob/main/examples/python/model-qa.py -o model-qa.py\n"
      ],
      "metadata": {
        "id": "cjWslWJahVXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python model-qa.py -m Phi-3-mini-128k-instruct-onnx/directml/directml-int4-awq-block-128"
      ],
      "metadata": {
        "id": "9XpcSmEpiHvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install hf_transfer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY5yM9pDtwZC",
        "outputId": "e4ad9b2a-b171-4405-933e-04d902208a95"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hf_transfer\n",
            "  Downloading hf_transfer-0.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hf_transfer\n",
            "Successfully installed hf_transfer-0.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install huggingface-hub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZCOXYequfE5",
        "outputId": "b85c077a-b9dd-4f7a-dfc9-14d7e65477cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download microsoft/Phi-3-mini-128k-instruct-onnx --local-dir . --local-dir-use-symlinks False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4etKnzuuhI_",
        "outputId": "e6079990-d824-4527-daed-617e470accb6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/.gitattributes to /root/.cache/huggingface/hub/tmpwi6ldc96\n",
            ".gitattributes: 100% 1.57k/1.57k [00:00<00:00, 7.79MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/LICENSE to /root/.cache/huggingface/hub/tmpp1imhif6\n",
            "LICENSE: 100% 12.5k/12.5k [00:00<00:00, 43.4MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/README.md to /root/.cache/huggingface/hub/tmpux0649en\n",
            "README.md: 100% 7.81k/7.81k [00:00<00:00, 28.2MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/added_tokens.json to /root/.cache/huggingface/hub/tmp51pyhf_q\n",
            "(…)n-block-32-acc-level-4/added_tokens.json: 100% 940/940 [00:00<00:00, 4.42MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/genai_config.json to /root/.cache/huggingface/hub/tmp9v2wtizg\n",
            "(…)n-block-32-acc-level-4/genai_config.json: 100% 1.61k/1.61k [00:00<00:00, 8.12MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/phi3-mini-128k-instruct-cpu-int4-rtn-block-32-acc-level-4.onnx to /root/.cache/huggingface/hub/tmpyhqjmgnp\n",
            "(…)t-cpu-int4-rtn-block-32-acc-level-4.onnx: 100% 52.2M/52.2M [00:01<00:00, 35.9MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/phi3-mini-128k-instruct-cpu-int4-rtn-block-32-acc-level-4.onnx.data to /root/.cache/huggingface/hub/tmp9tqifjqm\n",
            "(…)-int4-rtn-block-32-acc-level-4.onnx.data: 100% 2.72G/2.72G [00:39<00:00, 69.6MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/special_tokens_map.json to /root/.cache/huggingface/hub/tmpkik4kson\n",
            "(…)k-32-acc-level-4/special_tokens_map.json: 100% 623/623 [00:00<00:00, 3.07MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/tokenizer.json to /root/.cache/huggingface/hub/tmpf9k2e8p1\n",
            "(…)-rtn-block-32-acc-level-4/tokenizer.json: 100% 1.85M/1.85M [00:00<00:00, 29.1MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/tokenizer.model to /root/.cache/huggingface/hub/tmpzqb_35sh\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 4.50MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/tokenizer_config.json to /root/.cache/huggingface/hub/tmpug466hyx\n",
            "(…)ock-32-acc-level-4/tokenizer_config.json: 100% 7.92k/7.92k [00:00<00:00, 26.4MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32/added_tokens.json to /root/.cache/huggingface/hub/tmph97mvse2\n",
            "(…)/cpu-int4-rtn-block-32/added_tokens.json: 100% 940/940 [00:00<00:00, 4.54MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32/genai_config.json to /root/.cache/huggingface/hub/tmpxrda8eov\n",
            "(…)/cpu-int4-rtn-block-32/genai_config.json: 100% 1.60k/1.60k [00:00<00:00, 7.93MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32/phi3-mini-128k-instruct-cpu-int4-rtn-block-32.onnx to /root/.cache/huggingface/hub/tmpxsuctp12\n",
            "(…)128k-instruct-cpu-int4-rtn-block-32.onnx: 100% 52.2M/52.2M [00:00<00:00, 71.2MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32/phi3-mini-128k-instruct-cpu-int4-rtn-block-32.onnx.data to /root/.cache/huggingface/hub/tmpjjuyk5g_\n",
            "(…)instruct-cpu-int4-rtn-block-32.onnx.data: 100% 2.72G/2.72G [00:25<00:00, 106MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32/special_tokens_map.json to /root/.cache/huggingface/hub/tmpbitv088c\n",
            "(…)nt4-rtn-block-32/special_tokens_map.json: 100% 623/623 [00:00<00:00, 2.16MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32/tokenizer.json to /root/.cache/huggingface/hub/tmpwivbqrqb\n",
            "(…)ile/cpu-int4-rtn-block-32/tokenizer.json: 100% 1.85M/1.85M [00:00<00:00, 13.3MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32/tokenizer.model to /root/.cache/huggingface/hub/tmpnx8xaymc\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 7.36MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cpu_and_mobile/cpu-int4-rtn-block-32/tokenizer_config.json to /root/.cache/huggingface/hub/tmps0wrobgf\n",
            "(…)-int4-rtn-block-32/tokenizer_config.json: 100% 7.92k/7.92k [00:00<00:00, 21.4MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-fp16/added_tokens.json to /root/.cache/huggingface/hub/tmpo4_zyurd\n",
            "cuda/cuda-fp16/added_tokens.json: 100% 940/940 [00:00<00:00, 4.25MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-fp16/genai_config.json to /root/.cache/huggingface/hub/tmphbhos2lk\n",
            "cuda/cuda-fp16/genai_config.json: 100% 1.71k/1.71k [00:00<00:00, 8.30MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-fp16/phi3-mini-128k-instruct-cuda-fp16.onnx to /root/.cache/huggingface/hub/tmp6pkj829w\n",
            "phi3-mini-128k-instruct-cuda-fp16.onnx: 100% 26.1M/26.1M [00:00<00:00, 35.8MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-fp16/phi3-mini-128k-instruct-cuda-fp16.onnx.data to /root/.cache/huggingface/hub/tmpznhwozxj\n",
            "(…)3-mini-128k-instruct-cuda-fp16.onnx.data: 100% 7.64G/7.64G [01:03<00:00, 121MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-fp16/special_tokens_map.json to /root/.cache/huggingface/hub/tmpx1yjhxm9\n",
            "cuda/cuda-fp16/special_tokens_map.json: 100% 623/623 [00:00<00:00, 2.69MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-fp16/tokenizer.json to /root/.cache/huggingface/hub/tmpy224i_wj\n",
            "cuda/cuda-fp16/tokenizer.json: 100% 1.85M/1.85M [00:00<00:00, 10.7MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-fp16/tokenizer.model to /root/.cache/huggingface/hub/tmpyrctsj1b\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 11.3MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-fp16/tokenizer_config.json to /root/.cache/huggingface/hub/tmpwjpf64pd\n",
            "cuda/cuda-fp16/tokenizer_config.json: 100% 7.92k/7.92k [00:00<00:00, 26.0MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-int4-rtn-block-32/added_tokens.json to /root/.cache/huggingface/hub/tmpa553kigv\n",
            "(…)cuda-int4-rtn-block-32/added_tokens.json: 100% 940/940 [00:00<00:00, 3.55MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-int4-rtn-block-32/genai_config.json to /root/.cache/huggingface/hub/tmp_ji122wi\n",
            "(…)cuda-int4-rtn-block-32/genai_config.json: 100% 1.73k/1.73k [00:00<00:00, 9.00MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-int4-rtn-block-32/phi3-mini-128k-instruct-cuda-int4-rtn-block-32.onnx to /root/.cache/huggingface/hub/tmpt3nc3kzi\n",
            "(…)28k-instruct-cuda-int4-rtn-block-32.onnx: 100% 26.2M/26.2M [00:00<00:00, 58.2MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-int4-rtn-block-32/phi3-mini-128k-instruct-cuda-int4-rtn-block-32.onnx.data to /root/.cache/huggingface/hub/tmpyyf0y946\n",
            "(…)nstruct-cuda-int4-rtn-block-32.onnx.data: 100% 2.29G/2.29G [00:26<00:00, 87.4MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-int4-rtn-block-32/special_tokens_map.json to /root/.cache/huggingface/hub/tmp6i3bz7df\n",
            "(…)nt4-rtn-block-32/special_tokens_map.json: 100% 623/623 [00:00<00:00, 3.18MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-int4-rtn-block-32/tokenizer.json to /root/.cache/huggingface/hub/tmpo3onbcsv\n",
            "(…)da/cuda-int4-rtn-block-32/tokenizer.json: 100% 1.85M/1.85M [00:00<00:00, 13.5MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-int4-rtn-block-32/tokenizer.model to /root/.cache/huggingface/hub/tmpyuhr7gbt\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 11.3MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/cuda/cuda-int4-rtn-block-32/tokenizer_config.json to /root/.cache/huggingface/hub/tmpfe2uzlvt\n",
            "(…)-int4-rtn-block-32/tokenizer_config.json: 100% 7.92k/7.92k [00:00<00:00, 19.4MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/directml/directml-int4-awq-block-128/added_tokens.json to /root/.cache/huggingface/hub/tmp5uapxfm9\n",
            "(…)tml-int4-awq-block-128/added_tokens.json: 100% 980/980 [00:00<00:00, 5.31MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/directml/directml-int4-awq-block-128/genai_config.json to /root/.cache/huggingface/hub/tmpcdtdgx85\n",
            "(…)tml-int4-awq-block-128/genai_config.json: 100% 1.61k/1.61k [00:00<00:00, 7.77MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/directml/directml-int4-awq-block-128/model.onnx to /root/.cache/huggingface/hub/tmptlib12cz\n",
            "model.onnx: 100% 32.6M/32.6M [00:00<00:00, 115MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/directml/directml-int4-awq-block-128/model.onnx.data to /root/.cache/huggingface/hub/tmpqku1ybyl\n",
            "model.onnx.data: 100% 2.13G/2.13G [00:14<00:00, 150MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/directml/directml-int4-awq-block-128/special_tokens_map.json to /root/.cache/huggingface/hub/tmpp66eohar\n",
            "(…)t4-awq-block-128/special_tokens_map.json: 100% 656/656 [00:00<00:00, 3.06MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/directml/directml-int4-awq-block-128/tokenizer.json to /root/.cache/huggingface/hub/tmp0f481n3o\n",
            "(…)rectml-int4-awq-block-128/tokenizer.json: 100% 1.85M/1.85M [00:00<00:00, 10.5MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/directml/directml-int4-awq-block-128/tokenizer.model to /root/.cache/huggingface/hub/tmpg2iud4do\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 11.0MB/s]\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx/resolve/ca52cc9c32eaa82433d4b608d6477eb8e3fa0267/directml/directml-int4-awq-block-128/tokenizer_config.json to /root/.cache/huggingface/hub/tmp5aqmmxwj\n",
            "(…)int4-awq-block-128/tokenizer_config.json: 100% 8.27k/8.27k [00:00<00:00, 24.2MB/s]\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install --pre onnxruntime-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw5H5niFxQ3I",
        "outputId": "a65ca871-a2c6-43fb-cdcd-27e41f4ef44c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting onnxruntime-genai\n",
            "  Downloading onnxruntime_genai-0.2.0rc3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnxruntime-genai\n",
            "Successfully installed onnxruntime-genai-0.2.0rc3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/microsoft/onnxruntime-genai/main/examples/python/model-qa.py -o model-qa.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJjs5aBBxzMU",
        "outputId": "65658be4-1bae-4662-8a20-7323bd01ff9f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4094  100  4094    0     0  17340      0 --:--:-- --:--:-- --:--:-- 17421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python model-qa.py -m /content/cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4  -k 40 -p 0.95 -t 0.8 -r 1.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuxbqa5xzTgc",
        "outputId": "809372be-8382-4164-ce56-bc43fa26ff50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: salut, tu peux me dire qui es tu ?\n",
            "\n",
            "Output:  *\n",
            "\n",
            "\n",
            "### response ###\n",
            "\n",
            "La phrase que vous avez fournie est une demande de reconnaissance de l'identité de la personne qui parle. En français, pour demander qui est la personne qui parle, on utilise généralement l'expression \"C'est moi\". Cependant, dans le con"
          ]
        }
      ]
    }
  ]
}